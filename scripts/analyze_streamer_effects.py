"""
é…ä¿¡è€…åŠ¹æœã®åˆ†é›¢ - æ··äº¤å¤‰æ•°ã®åˆ¶å¾¡
Streamer Effect Separation - Confounding Variable Control

ç›®çš„:
- é…ä¿¡è€…ã®å€‹äººç‰¹æ€§ï¼ˆé…ä¿¡ã‚¹ã‚¿ã‚¤ãƒ«ã€è¦–è´è€…å±¤ï¼‰ã‚’åˆ¶å¾¡
- è©¦åˆç‰¹æ€§ã®ç´”ç²‹ãªåŠ¹æœã‚’æ¨å®š
- æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹éšå±¤çš„åˆ†æ
"""

import pandas as pd
import numpy as np
from pathlib import Path
from scipy import stats
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict
import warnings
import sys
import io
warnings.filterwarnings('ignore')

# Windows PowerShellã®æ–‡å­—åŒ–ã‘å¯¾ç­–
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# statsmodelsã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆæ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«ç”¨ï¼‰
try:
    import statsmodels.api as sm
    import statsmodels.formula.api as smf
    from statsmodels.regression.mixed_linear_model import MixedLM
    STATSMODELS_AVAILABLE = True
except ImportError:
    STATSMODELS_AVAILABLE = False
    print("âš ï¸ statsmodelsãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚pip install statsmodels ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
DATA_DIR = Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\å¤§å­¦\4å¹´\ã‚¼ãƒŸ\watching_style_analysis\data\football")
OUTPUT_DIR = Path(r"G:\ãƒã‚¤ãƒ‰ãƒ©ã‚¤ãƒ–\å¤§å­¦\4å¹´\ã‚¼ãƒŸ\watching_style_analysis\output\streamer_effects")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# è©¦åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆæ—¥æœ¬èªãƒ•ã‚©ãƒ«ãƒ€åã«ãƒãƒƒãƒ”ãƒ³ã‚°ï¼‰
MATCH_METADATA = {
    "Real_Madrid_vs_Barcelona": {"folder": "ãƒ¬ã‚¢ãƒ«ãƒãƒ‰ãƒªãƒ¼ãƒ‰vsãƒãƒ«ã‚»ãƒ­ãƒŠ", "tier": 1, "importance_score": 10},
    "Brazil_vs_Japan": {"folder": "ãƒ–ãƒ©ã‚¸ãƒ«vsæ—¥æœ¬", "tier": 2, "importance_score": 8},
    "Brighton_vs_Man_City": {"folder": "ãƒ–ãƒ©ã‚¤ãƒˆãƒ³vsãƒãƒ³ãƒã‚§ã‚¹ã‚¿ãƒ¼ã‚·ãƒ†ã‚£", "tier": 3, "importance_score": 5},
    "Real_Sociedad_vs_Real_Madrid": {"folder": "ãƒ¬ã‚¢ãƒ«ã‚½ã‚·ã‚¨ãƒ€vsãƒ¬ã‚¢ãƒ«ãƒãƒ‰ãƒªãƒ¼ãƒ‰", "tier": 3, "importance_score": 5},
    "Leeds_vs_Spurs": {"folder": "ãƒªãƒ¼ã‚ºãƒ¦ãƒŠã‚¤ãƒ†ãƒƒãƒ‰vsã‚¹ãƒ‘ãƒ¼ã‚º", "tier": 4, "importance_score": 3},
    "PSG_vs_Inter_Miami": {"folder": "ãƒ‘ãƒªã‚µãƒ³ã‚¸ã‚§ãƒ«ãƒãƒ³vsã‚¤ãƒ³ãƒ†ãƒ«ãƒã‚¤ã‚¢ãƒŸ", "tier": 4, "importance_score": 2}
}

def load_all_streams():
    """
    å…¨é…ä¿¡ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    
    Returns:
    --------
    pd.DataFrame : å…¨é…ä¿¡ãƒ‡ãƒ¼ã‚¿
    """
    all_streams = []
    
    for match, metadata in MATCH_METADATA.items():
        folder_path = DATA_DIR / metadata['folder']
        
        # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        csv_files = list(folder_path.glob("*_chat_log.csv"))
        if not csv_files:
            csv_files = list(folder_path.glob("*.csv"))
        
        if not csv_files:
            continue
        
        for csv_file in csv_files:
            try:
                df = pd.read_csv(csv_file, encoding='utf-8')
                
                # ã‚«ãƒ©ãƒ åã‚’æ­£è¦åŒ–
                if 'message' in df.columns:
                    df.rename(columns={'message': 'comment'}, inplace=True)
                
                if 'comment' not in df.columns:
                    continue
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
                df['match'] = match
                df['stream_source'] = csv_file.stem
                df['tier'] = metadata['tier']
                df['importance_score'] = metadata['importance_score']
                
                all_streams.append(df)
            except Exception as e:
                print(f"âš ï¸ {csv_file.name}: èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ - {e}")
                continue
    
    if not all_streams:
        return None
    
    combined_df = pd.concat(all_streams, ignore_index=True)
    return combined_df

def calculate_stream_metrics(df):
    """
    é…ä¿¡ãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™ã‚’è¨ˆç®—
    
    Parameters:
    -----------
    df : pd.DataFrame
        é…ä¿¡ãƒ‡ãƒ¼ã‚¿
        
    Returns:
    --------
    dict : å„ç¨®æŒ‡æ¨™
    """
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ datetime ã«å¤‰æ›
    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
    df = df.dropna(subset=['timestamp'])
    df = df.sort_values('timestamp')
    
    # é…ä¿¡æ™‚é–“
    duration_minutes = (df['timestamp'].max() - df['timestamp'].min()).total_seconds() / 60
    
    # åŸºæœ¬æŒ‡æ¨™
    total_comments = len(df)
    cpm = total_comments / duration_minutes if duration_minutes > 0 else np.nan
    
    # ã‚³ãƒ¡ãƒ³ãƒˆé•·
    avg_length = df['comment'].str.len().mean()
    
    # çµµæ–‡å­—ç‡
    emoji_pattern = r'[\U0001F600-\U0001F64F\U0001F300-\U0001F5FF\U0001F680-\U0001F6FF\U0001F1E0-\U0001F1FF\U00002702-\U000027B0\U000024C2-\U0001F251]+'
    emoji_rate = df['comment'].str.contains(emoji_pattern, regex=True, na=False).sum() / total_comments * 100
    
    # ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼
    word_freq = defaultdict(int)
    for comment in df['comment'].dropna():
        words = str(comment).split()
        for word in words:
            word_freq[word] += 1
    
    total_words = sum(word_freq.values())
    if total_words > 0:
        probs = np.array(list(word_freq.values())) / total_words
        entropy = -np.sum(probs * np.log2(probs + 1e-10))
    else:
        entropy = np.nan
    
    return {
        'cpm': cpm,
        'avg_comment_length': avg_length,
        'emoji_rate': emoji_rate,
        'entropy': entropy,
        'total_comments': total_comments,
        'duration_minutes': duration_minutes
    }

def identify_streamer_profiles(stream_metrics_df):
    """
    é…ä¿¡è€…ã®ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
    
    Parameters:
    -----------
    stream_metrics_df : pd.DataFrame
        é…ä¿¡ãƒ¬ãƒ™ãƒ«ã®æŒ‡æ¨™
        
    Returns:
    --------
    pd.DataFrame : é…ä¿¡è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
    """
    print("\n" + "="*80)
    print("é…ä¿¡è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®š...")
    print("="*80)
    
    # è¤‡æ•°è©¦åˆã«å‡ºç¾ã™ã‚‹é…ä¿¡è€…
    streamer_counts = stream_metrics_df['stream_source'].value_counts()
    multi_match_streamers = streamer_counts[streamer_counts > 1].index.tolist()
    
    print(f"\nâœ… è¤‡æ•°è©¦åˆã«å‡ºç¾ã™ã‚‹é…ä¿¡è€…: {len(multi_match_streamers)}å")
    
    if multi_match_streamers:
        print("\né…ä¿¡è€…åˆ¥ã®å¹³å‡æŒ‡æ¨™:")
        for streamer in multi_match_streamers:
            streamer_data = stream_metrics_df[stream_metrics_df['stream_source'] == streamer]
            print(f"\n  {streamer}:")
            print(f"    å‡ºç¾è©¦åˆæ•°: {len(streamer_data)}")
            print(f"    å¹³å‡CPM: {streamer_data['cpm'].mean():.2f}")
            print(f"    å¹³å‡ã‚³ãƒ¡ãƒ³ãƒˆé•·: {streamer_data['avg_comment_length'].mean():.1f}")
            print(f"    å¹³å‡çµµæ–‡å­—ç‡: {streamer_data['emoji_rate'].mean():.1f}%")
    
    # é…ä¿¡è€…ã®å¹³å‡ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è¨ˆç®—
    streamer_profiles = stream_metrics_df.groupby('stream_source').agg({
        'cpm': 'mean',
        'avg_comment_length': 'mean',
        'emoji_rate': 'mean',
        'entropy': 'mean',
        'total_comments': 'sum'
    }).reset_index()
    
    streamer_profiles['appearance_count'] = stream_metrics_df.groupby('stream_source').size().values
    
    return streamer_profiles

def fit_mixed_effects_models(stream_metrics_df):
    """
    æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚£ãƒƒãƒˆ
    
    Parameters:
    -----------
    stream_metrics_df : pd.DataFrame
        é…ä¿¡ãƒ¬ãƒ™ãƒ«ã®æŒ‡æ¨™
        
    Returns:
    --------
    dict : ãƒ¢ãƒ‡ãƒ«çµæœ
    """
    if not STATSMODELS_AVAILABLE:
        print("\nâš ï¸ statsmodelsãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return {}
    
    print("\n" + "="*80)
    print("æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒˆ...")
    print("="*80)
    
    # é…ä¿¡è€…ã‚’å¤‰é‡åŠ¹æœã€è©¦åˆé‡è¦åº¦ã‚’å›ºå®šåŠ¹æœã¨ã™ã‚‹
    results = {}
    
    dependent_vars = ['cpm', 'avg_comment_length', 'emoji_rate', 'entropy']
    
    for dep_var in dependent_vars:
        print(f"\nğŸ“Š å¾“å±å¤‰æ•°: {dep_var}")
        
        # æ¬ æå€¤ã‚’é™¤å¤–
        model_data = stream_metrics_df[['stream_source', 'importance_score', dep_var]].dropna()
        
        if len(model_data) < 10:
            print(f"  âš ï¸ ã‚µãƒ³ãƒ—ãƒ«æ•°ä¸è¶³: N={len(model_data)}")
            continue
        
        try:
            # æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«: å¾“å±å¤‰æ•° ~ é‡è¦åº¦ + (1 | é…ä¿¡è€…)
            model = MixedLM.from_formula(
                f'{dep_var} ~ importance_score',
                data=model_data,
                groups=model_data['stream_source']
            )
            
            result = model.fit(reml=False)  # MLæ¨å®š
            
            print(f"\n  å›ºå®šåŠ¹æœï¼ˆé‡è¦åº¦ã®å½±éŸ¿ï¼‰:")
            print(f"    ä¿‚æ•°: {result.params['importance_score']:.4f}")
            print(f"    på€¤: {result.pvalues['importance_score']:.4f}")
            
            print(f"\n  å¤‰é‡åŠ¹æœï¼ˆé…ä¿¡è€…ã®ã°ã‚‰ã¤ãï¼‰:")
            print(f"    ÏƒÂ²_é…ä¿¡è€…: {result.cov_re.values[0][0]:.4f}")
            print(f"    ÏƒÂ²_æ®‹å·®: {result.scale:.4f}")
            
            # ICCï¼ˆç´šå†…ç›¸é–¢ä¿‚æ•°ï¼‰- é…ä¿¡è€…åŠ¹æœã®å¤§ãã•
            icc = result.cov_re.values[0][0] / (result.cov_re.values[0][0] + result.scale)
            print(f"    ICC: {icc:.4f} ({icc*100:.1f}%ãŒé…ä¿¡è€…ã«ã‚ˆã‚‹)")
            
            results[dep_var] = {
                'fixed_effect': result.params['importance_score'],
                'fixed_pvalue': result.pvalues['importance_score'],
                'random_var': result.cov_re.values[0][0],
                'residual_var': result.scale,
                'icc': icc,
                'aic': result.aic,
                'bic': result.bic
            }
            
        except Exception as e:
            print(f"  âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚£ãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return results

def compare_controlled_vs_uncontrolled(stream_metrics_df):
    """
    é…ä¿¡è€…åŠ¹æœã‚’åˆ¶å¾¡ã—ãŸå ´åˆã¨ã—ãªã„å ´åˆã®æ¯”è¼ƒ
    
    Parameters:
    -----------
    stream_metrics_df : pd.DataFrame
        é…ä¿¡ãƒ¬ãƒ™ãƒ«ã®æŒ‡æ¨™
        
    Returns:
    --------
    dict : æ¯”è¼ƒçµæœ
    """
    print("\n" + "="*80)
    print("é…ä¿¡è€…åŠ¹æœã®åˆ¶å¾¡å‰å¾Œã®æ¯”è¼ƒ...")
    print("="*80)
    
    results = {}
    
    dependent_vars = ['cpm', 'avg_comment_length', 'emoji_rate', 'entropy']
    
    for dep_var in dependent_vars:
        print(f"\nğŸ“Š {dep_var}:")
        
        model_data = stream_metrics_df[['importance_score', dep_var]].dropna()
        
        if len(model_data) < 10:
            continue
        
        # 1. å˜ç´”ãªç›¸é–¢ï¼ˆé…ä¿¡è€…åŠ¹æœã‚’åˆ¶å¾¡ã—ãªã„ï¼‰
        corr, p_corr = stats.spearmanr(model_data['importance_score'], model_data[dep_var])
        print(f"\n  é…ä¿¡è€…åŠ¹æœã‚’åˆ¶å¾¡ã—ãªã„:")
        print(f"    Spearmanç›¸é–¢: Ï={corr:.3f}, p={p_corr:.4f}")
        
        # 2. é…ä¿¡è€…å†…ã§ã®ç›¸é–¢ï¼ˆé…ä¿¡è€…åŠ¹æœã‚’åˆ¶å¾¡ï¼‰
        within_streamer_corrs = []
        
        for streamer in stream_metrics_df['stream_source'].unique():
            streamer_data = stream_metrics_df[stream_metrics_df['stream_source'] == streamer]
            
            if len(streamer_data) < 2:  # æœ€ä½2è©¦åˆå¿…è¦
                continue
            
            streamer_corr, _ = stats.spearmanr(
                streamer_data['importance_score'], 
                streamer_data[dep_var]
            )
            
            if not np.isnan(streamer_corr):
                within_streamer_corrs.append(streamer_corr)
        
        if within_streamer_corrs:
            mean_within_corr = np.mean(within_streamer_corrs)
            print(f"\n  é…ä¿¡è€…åŠ¹æœã‚’åˆ¶å¾¡:")
            print(f"    å¹³å‡é…ä¿¡è€…å†…ç›¸é–¢: Ï={mean_within_corr:.3f}")
            print(f"    N={len(within_streamer_corrs)}åã®é…ä¿¡è€…")
        else:
            mean_within_corr = np.nan
            print(f"\n  âš ï¸ é…ä¿¡è€…å†…ç›¸é–¢ã‚’è¨ˆç®—ã§ãã¾ã›ã‚“ï¼ˆè¤‡æ•°è©¦åˆå‡ºæ¼”ã®é…ä¿¡è€…ä¸è¶³ï¼‰")
        
        results[dep_var] = {
            'uncontrolled_corr': corr,
            'uncontrolled_pvalue': p_corr,
            'controlled_corr': mean_within_corr,
            'n_streamers': len(within_streamer_corrs) if within_streamer_corrs else 0
        }
    
    return results

def create_visualizations(stream_metrics_df, mixed_results, comparison_results):
    """
    é…ä¿¡è€…åŠ¹æœã®å¯è¦–åŒ–
    
    Parameters:
    -----------
    stream_metrics_df : pd.DataFrame
        é…ä¿¡ãƒ¬ãƒ™ãƒ«ã®æŒ‡æ¨™
    mixed_results : dict
        æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«çµæœ
    comparison_results : dict
        åˆ¶å¾¡å‰å¾Œã®æ¯”è¼ƒçµæœ
    """
    print("\n" + "="*80)
    print("å¯è¦–åŒ–ä½œæˆä¸­...")
    print("="*80)
    
    # 1. ICCã®å¯è¦–åŒ–ï¼ˆé…ä¿¡è€…åŠ¹æœã®å¤§ãã•ï¼‰
    if mixed_results:
        fig, ax = plt.subplots(figsize=(10, 6))
        
        metrics = list(mixed_results.keys())
        iccs = [mixed_results[m]['icc'] for m in metrics]
        
        colors = ['#FF6B6B' if icc > 0.5 else '#4ECDC4' for icc in iccs]
        bars = ax.barh(metrics, iccs, color=colors, alpha=0.7, edgecolor='black')
        
        ax.axvline(0.5, color='red', linestyle='--', linewidth=1.5, 
                   label='ICC=0.5 (50% threshold)', alpha=0.7)
        
        ax.set_xlabel('ICC (Intraclass Correlation Coefficient)', fontsize=12, fontweight='bold')
        ax.set_title('é…ä¿¡è€…åŠ¹æœã®å¤§ãã•\nStreamer Effect Magnitude (ICC)', 
                     fontsize=14, fontweight='bold')
        ax.set_xlim(0, 1)
        ax.legend(loc='lower right')
        ax.grid(True, alpha=0.3, axis='x')
        
        # å€¤ã‚’ãƒãƒ¼ã«è¡¨ç¤º
        for i, (metric, icc) in enumerate(zip(metrics, iccs)):
            ax.text(icc + 0.02, i, f'{icc*100:.1f}%', va='center', fontsize=10, fontweight='bold')
        
        plt.tight_layout()
        output_path = OUTPUT_DIR / "streamer_effect_icc.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"  âœ“ ICCå¯è¦–åŒ–ä¿å­˜: {output_path.name}")
        plt.close()
    
    # 2. é…ä¿¡è€…åˆ¥ã®æ•£å¸ƒå›³
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))
    fig.suptitle('é…ä¿¡è€…åˆ¥ã®ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆæŒ‡æ¨™\nEngagement Metrics by Streamer', 
                 fontsize=16, fontweight='bold')
    
    metrics_to_plot = [
        ('cpm', 'Comments Per Minute (CPM)', axes[0, 0]),
        ('avg_comment_length', 'Average Comment Length (characters)', axes[0, 1]),
        ('emoji_rate', 'Emoji Usage Rate (%)', axes[1, 0]),
        ('entropy', 'Comment Diversity (Entropy)', axes[1, 1])
    ]
    
    # é…ä¿¡è€…ã”ã¨ã«è‰²ã‚’å‰²ã‚Šå½“ã¦
    unique_streamers = stream_metrics_df['stream_source'].unique()
    colors = sns.color_palette('husl', len(unique_streamers))
    streamer_colors = dict(zip(unique_streamers, colors))
    
    for metric, title, ax in metrics_to_plot:
        for streamer in unique_streamers:
            streamer_data = stream_metrics_df[stream_metrics_df['stream_source'] == streamer]
            
            if len(streamer_data) < 1:
                continue
            
            ax.scatter(
                streamer_data['importance_score'], 
                streamer_data[metric],
                color=streamer_colors[streamer],
                alpha=0.6,
                s=100,
                edgecolors='black',
                linewidth=0.5,
                label=streamer if len(streamer_data) > 1 else ''
            )
            
            # è¤‡æ•°è©¦åˆå‡ºæ¼”ã®é…ä¿¡è€…ã¯ç·šã§çµã¶
            if len(streamer_data) > 1:
                streamer_data_sorted = streamer_data.sort_values('importance_score')
                ax.plot(
                    streamer_data_sorted['importance_score'],
                    streamer_data_sorted[metric],
                    color=streamer_colors[streamer],
                    alpha=0.3,
                    linewidth=1
                )
        
        ax.set_xlabel('Match Importance Score', fontsize=10, fontweight='bold')
        ax.set_ylabel(title.split('(')[0].strip(), fontsize=10, fontweight='bold')
        ax.set_title(title, fontsize=11, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        # å‡¡ä¾‹ã¯è¡¨ç¤ºã—ãªã„ï¼ˆé…ä¿¡è€…ãŒå¤šã™ãã‚‹å ´åˆãŒã‚ã‚‹ãŸã‚ï¼‰
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / "streamer_effect_scatter.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ æ•£å¸ƒå›³ä¿å­˜: {output_path.name}")
    plt.close()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("="*80)
    print("é…ä¿¡è€…åŠ¹æœã®åˆ†é›¢ - Streamer Effect Separation")
    print("="*80)
    
    print("\nğŸš€ åˆ†æé–‹å§‹\n")
    
    # å…¨é…ä¿¡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
    print("ğŸ“‚ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    all_data = load_all_streams()
    
    if all_data is None:
        print("\nâŒ ãƒ‡ãƒ¼ã‚¿ãŒèª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    print(f"âœ“ {len(all_data):,} ã‚³ãƒ¡ãƒ³ãƒˆèª­ã¿è¾¼ã¿å®Œäº†")
    print(f"  è©¦åˆæ•°: {all_data['match'].nunique()}")
    print(f"  é…ä¿¡æ•°: {all_data['stream_source'].nunique()}")
    
    # é…ä¿¡ãƒ¬ãƒ™ãƒ«ã®æŒ‡æ¨™ã‚’è¨ˆç®—
    print("\n" + "="*80)
    print("é…ä¿¡ãƒ¬ãƒ™ãƒ«ã®æŒ‡æ¨™è¨ˆç®—...")
    print("="*80)
    
    stream_metrics = []
    
    for (match, stream), group in all_data.groupby(['match', 'stream_source']):
        metrics = calculate_stream_metrics(group)
        metrics['match'] = match
        metrics['stream_source'] = stream
        metrics['tier'] = group['tier'].iloc[0]
        metrics['importance_score'] = group['importance_score'].iloc[0]
        stream_metrics.append(metrics)
    
    stream_metrics_df = pd.DataFrame(stream_metrics)
    
    # æ¬ æå€¤ã‚’é™¤å¤–
    stream_metrics_df = stream_metrics_df.dropna(subset=['cpm', 'avg_comment_length', 'emoji_rate', 'entropy'])
    
    print(f"\nâœ“ {len(stream_metrics_df)} é…ä¿¡ã®æŒ‡æ¨™è¨ˆç®—å®Œäº†")
    
    # çµæœã‚’ä¿å­˜
    output_csv = OUTPUT_DIR / "stream_metrics_with_match_info.csv"
    stream_metrics_df.to_csv(output_csv, index=False, encoding='utf-8-sig')
    print(f"âœ“ é…ä¿¡æŒ‡æ¨™ä¿å­˜: {output_csv}")
    
    # é…ä¿¡è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®š
    streamer_profiles = identify_streamer_profiles(stream_metrics_df)
    
    # é…ä¿¡è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
    profile_csv = OUTPUT_DIR / "streamer_profiles.csv"
    streamer_profiles.to_csv(profile_csv, index=False, encoding='utf-8-sig')
    print(f"\nâœ“ é…ä¿¡è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {profile_csv}")
    
    # æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«ã®ãƒ•ã‚£ãƒƒãƒˆ
    mixed_results = fit_mixed_effects_models(stream_metrics_df)
    
    # åˆ¶å¾¡å‰å¾Œã®æ¯”è¼ƒ
    comparison_results = compare_controlled_vs_uncontrolled(stream_metrics_df)
    
    # å¯è¦–åŒ–
    create_visualizations(stream_metrics_df, mixed_results, comparison_results)
    
    # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
    create_summary_report(stream_metrics_df, mixed_results, comparison_results, streamer_profiles)
    
    print("\n" + "="*80)
    print("âœ… é…ä¿¡è€…åŠ¹æœã®åˆ†é›¢ å®Œäº†")
    print("="*80)

def create_summary_report(stream_metrics_df, mixed_results, comparison_results, streamer_profiles):
    """ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
    report = []
    report.append("# é…ä¿¡è€…åŠ¹æœã®åˆ†é›¢ - Streamer Effect Separation Report\n")
    report.append(f"**åˆ†ææ—¥æ™‚**: {pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}\n")
    report.append(f"**æ–¹æ³•**: æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«ï¼ˆé…ä¿¡è€…ã‚’å¤‰é‡åŠ¹æœã¨ã—ã¦åˆ¶å¾¡ï¼‰\n")
    report.append("---\n\n")
    
    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    report.append("## ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦\n\n")
    report.append(f"- **ç·é…ä¿¡æ•°**: {len(stream_metrics_df)}\n")
    report.append(f"- **è©¦åˆæ•°**: {stream_metrics_df['match'].nunique()}\n")
    report.append(f"- **é…ä¿¡è€…æ•°**: {stream_metrics_df['stream_source'].nunique()}\n")
    report.append(f"- **è¤‡æ•°è©¦åˆå‡ºæ¼”é…ä¿¡è€…**: {len(streamer_profiles[streamer_profiles['appearance_count'] > 1])}å\n\n")
    
    # æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«çµæœ
    if mixed_results:
        report.append("## ğŸ¯ æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«çµæœ\n\n")
        report.append("é…ä¿¡è€…ã‚’å¤‰é‡åŠ¹æœã¨ã—ã¦åˆ¶å¾¡ã—ã€è©¦åˆé‡è¦åº¦ã®ç´”ç²‹ãªåŠ¹æœã‚’æ¨å®š\n\n")
        
        report.append("| æŒ‡æ¨™ | é‡è¦åº¦ä¿‚æ•° | på€¤ | ICC | é…ä¿¡è€…åŠ¹æœ(%) |\n")
        report.append("|------|-----------|-----|-----|-------------|\n")
        
        for metric, result in mixed_results.items():
            sig_mark = "**æœ‰æ„**" if result['fixed_pvalue'] < 0.05 else "éæœ‰æ„"
            report.append(f"| {metric} | {result['fixed_effect']:.4f} | "
                         f"{result['fixed_pvalue']:.4f} ({sig_mark}) | "
                         f"{result['icc']:.3f} | {result['icc']*100:.1f}% |\n")
        
        report.append("\n**ICC (Intraclass Correlation)**: å…¨ä½“ã®ã°ã‚‰ã¤ãã®ã†ã¡é…ä¿¡è€…ã«ã‚ˆã‚‹éƒ¨åˆ†\n\n")
    
    # åˆ¶å¾¡å‰å¾Œã®æ¯”è¼ƒ
    if comparison_results:
        report.append("## ğŸ“ˆ é…ä¿¡è€…åŠ¹æœã®åˆ¶å¾¡å‰å¾Œã®æ¯”è¼ƒ\n\n")
        
        report.append("| æŒ‡æ¨™ | åˆ¶å¾¡ãªã—ç›¸é–¢ | åˆ¶å¾¡ã‚ã‚Šç›¸é–¢ | å·® |\n")
        report.append("|------|-------------|-------------|----|\n")
        
        for metric, result in comparison_results.items():
            diff = result['uncontrolled_corr'] - result['controlled_corr']
            diff_str = f"{diff:+.3f}" if not np.isnan(diff) else "N/A"
            controlled_str = f"{result['controlled_corr']:.3f}" if not np.isnan(result['controlled_corr']) else "N/A"
            
            report.append(f"| {metric} | {result['uncontrolled_corr']:.3f} | "
                         f"{controlled_str} | {diff_str} |\n")
        
        report.append("\n")
    
    # é…ä¿¡è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«
    report.append("## ğŸ‘¥ é…ä¿¡è€…ãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆä¸Šä½10åï¼‰\n\n")
    
    top_streamers = streamer_profiles.nlargest(10, 'total_comments')
    
    report.append("| é…ä¿¡è€… | å‡ºç¾å›æ•° | å¹³å‡CPM | å¹³å‡ã‚³ãƒ¡ãƒ³ãƒˆé•· | çµµæ–‡å­—ç‡(%) |\n")
    report.append("|--------|---------|---------|---------------|------------|\n")
    
    for _, streamer in top_streamers.iterrows():
        report.append(f"| {streamer['stream_source']} | {streamer['appearance_count']:.0f} | "
                     f"{streamer['cpm']:.1f} | {streamer['avg_comment_length']:.1f} | "
                     f"{streamer['emoji_rate']:.1f} |\n")
    
    report.append("\n")
    
    # ä¸»è¦ãªç™ºè¦‹
    report.append("## ğŸ” ä¸»è¦ãªç™ºè¦‹\n\n")
    
    if mixed_results:
        # ICCæœ€å¤§ã®æŒ‡æ¨™
        max_icc_metric = max(mixed_results.items(), key=lambda x: x[1]['icc'])
        report.append(f"### é…ä¿¡è€…åŠ¹æœãŒæœ€ã‚‚å¤§ãã„æŒ‡æ¨™\n\n")
        report.append(f"**{max_icc_metric[0]}**: ICC={max_icc_metric[1]['icc']:.3f} ")
        report.append(f"({max_icc_metric[1]['icc']*100:.1f}%ãŒé…ä¿¡è€…ã«ã‚ˆã‚‹)\n\n")
        
        # æœ‰æ„ãªå›ºå®šåŠ¹æœ
        sig_effects = [m for m, r in mixed_results.items() if r['fixed_pvalue'] < 0.05]
        if sig_effects:
            report.append(f"### é…ä¿¡è€…åŠ¹æœã‚’åˆ¶å¾¡ã—ã¦ã‚‚æœ‰æ„ãªè©¦åˆé‡è¦åº¦ã®åŠ¹æœ\n\n")
            for metric in sig_effects:
                result = mixed_results[metric]
                report.append(f"- **{metric}**: ä¿‚æ•°={result['fixed_effect']:.4f}, p={result['fixed_pvalue']:.4f}\n")
            report.append("\n")
    
    # æ–¹æ³•è«–çš„æ„ç¾©
    report.append("## ğŸ”¬ æ–¹æ³•è«–çš„æ„ç¾©\n\n")
    report.append("### æ··äº¤å¤‰æ•°ã®å•é¡Œ\n")
    report.append("- é…ä¿¡è€…ã«ã‚ˆã£ã¦è¦–è´è€…å±¤ã€é…ä¿¡ã‚¹ã‚¿ã‚¤ãƒ«ã€è¨€èªãŒç•°ãªã‚‹\n")
    report.append("- è©¦åˆé‡è¦åº¦ã¨é…ä¿¡è€…ã®é¸æŠãŒäº¤çµ¡ã—ã¦ã„ã‚‹å¯èƒ½æ€§\n")
    report.append("- å˜ç´”ãªæ¯”è¼ƒã§ã¯è©¦åˆåŠ¹æœã¨é…ä¿¡è€…åŠ¹æœã‚’åˆ†é›¢ã§ããªã„\n\n")
    
    report.append("### æœ¬æ‰‹æ³•ã®åˆ©ç‚¹\n")
    report.append("- **æ··åˆåŠ¹æœãƒ¢ãƒ‡ãƒ«**: é…ä¿¡è€…ã‚’å¤‰é‡åŠ¹æœã¨ã—ã¦éšå±¤çš„ã«ãƒ¢ãƒ‡ãƒ«åŒ–\n")
    report.append("- **ICC**: é…ä¿¡è€…åŠ¹æœã®å¤§ãã•ã‚’å®šé‡åŒ–\n")
    report.append("- **ç´”ç²‹ãªè©¦åˆåŠ¹æœ**: é…ä¿¡è€…ã®ã°ã‚‰ã¤ãã‚’åˆ¶å¾¡ã—ãŸæ¨å®š\n\n")
    
    # ä»Šå¾Œã®å±•é–‹
    report.append("## ğŸš€ ä»Šå¾Œã®å±•é–‹\n\n")
    report.append("1. **ã‚ˆã‚Šè¤‡é›‘ãªéšå±¤ãƒ¢ãƒ‡ãƒ«**\n")
    report.append("   - è©¦åˆå†…ã«é…ä¿¡è€…ãŒãƒã‚¹ãƒˆã•ã‚ŒãŸ3ãƒ¬ãƒ™ãƒ«ãƒ¢ãƒ‡ãƒ«\n")
    report.append("   - æ™‚é–“å¤‰å‹•ã‚’è€ƒæ…®ã—ãŸç¸¦æ–­çš„æ··åˆãƒ¢ãƒ‡ãƒ«\n\n")
    
    report.append("2. **é…ä¿¡è€…ç‰¹æ€§ã®è©³ç´°åˆ†æ**\n")
    report.append("   - é…ä¿¡ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆå®Ÿæ³å‹ vs è§£èª¬å‹ï¼‰ã®åˆ†é¡\n")
    report.append("   - è¦–è´è€…å±¤ï¼ˆã‚«ã‚¸ãƒ¥ã‚¢ãƒ« vs ãƒãƒ¼ãƒ‰ã‚³ã‚¢ï¼‰ã®æ¨å®š\n\n")
    
    report.append("3. **äº¤äº’ä½œç”¨åŠ¹æœ**\n")
    report.append("   - è©¦åˆé‡è¦åº¦ Ã— é…ä¿¡è€…ã‚¹ã‚¿ã‚¤ãƒ«ã®äº¤äº’ä½œç”¨\n")
    report.append("   - é…ä¿¡è€…ã«ã‚ˆã£ã¦ç•°ãªã‚‹è©¦åˆé‡è¦åº¦ã®åŠ¹æœ\n\n")
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
    report_path = OUTPUT_DIR / "STREAMER_EFFECT_ANALYSIS_SUMMARY.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.writelines(report)
    
    print(f"\nâœ“ ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")

if __name__ == "__main__":
    main()
