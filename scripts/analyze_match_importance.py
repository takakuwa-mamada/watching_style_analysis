#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è©¦åˆé‡è¦åº¦ã¨æ„Ÿæƒ…è¡¨ç¾ã®é–¢ä¿‚ã‚’åˆ†æã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä»®èª¬:
- H1: è©¦åˆã®é‡è¦åº¦ãŒé«˜ã„ã»ã©ã€æ„Ÿæƒ…è¡¨ç¾ï¼ˆçµµæ–‡å­—ã€æ„Ÿå˜†ç¬¦ï¼‰ã®ä½¿ç”¨ç‡ãŒé«˜ã„
- H2: é‡è¦ãªè©¦åˆã§ã¯ã€ãƒãƒ¼ã‚¹ãƒˆå¼·åº¦ï¼ˆç¬é–“çš„ãªã‚³ãƒ¡ãƒ³ãƒˆæ€¥å¢—ï¼‰ãŒå¤§ãã„
- H3: é‡è¦ãªè©¦åˆã§ã¯ã€ãƒˆãƒ”ãƒƒã‚¯ã®å¤šæ§˜æ€§ãŒé«˜ã„ï¼ˆå¤šè§’çš„ãªè­°è«–ï¼‰

åˆ†ææ‰‹æ³•:
- Kruskal-Wallisæ¤œå®šï¼ˆ4ç¾¤æ¯”è¼ƒï¼‰
- Dunn's post-hoc testï¼ˆå¤šé‡æ¯”è¼ƒï¼‰
- Cohen's dåŠ¹æœé‡è¨ˆç®—
- å¯è¦–åŒ–ï¼šãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆã€ãƒã‚¤ã‚ªãƒªãƒ³ãƒ—ãƒ­ãƒƒãƒˆã€åŠ¹æœé‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
"""

import pandas as pd
import numpy as np
from pathlib import Path
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import kruskal, mannwhitneyu
import warnings
warnings.filterwarnings('ignore')

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®š
plt.rcParams['font.sans-serif'] = ['Yu Gothic', 'Meiryo', 'MS Gothic']
plt.rcParams['axes.unicode_minus'] = False

# ãƒ‘ã‚¹è¨­å®š
BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / "data"
OUTPUT_DIR = BASE_DIR / "output" / "match_importance_analysis"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

print("=" * 80)
print("è©¦åˆé‡è¦åº¦åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ - Match Importance Analysis")
print("=" * 80)


def load_match_metadata():
    """è©¦åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    metadata_path = DATA_DIR / "match_metadata.csv"
    df = pd.read_csv(metadata_path, encoding='utf-8-sig')
    print(f"\nâœ“ è©¦åˆãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(df)} è©¦åˆ")
    return df


def load_chat_logs(match_folder):
    """æŒ‡å®šè©¦åˆãƒ•ã‚©ãƒ«ãƒ€ã®ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚€"""
    folder_path = DATA_DIR / "football" / match_folder
    
    if not folder_path.exists():
        print(f"  âš  ãƒ•ã‚©ãƒ«ãƒ€ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {match_folder}")
        return None
    
    all_comments = []
    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆè¤‡æ•°ãƒ‘ã‚¿ãƒ¼ãƒ³å¯¾å¿œï¼‰
    csv_files = list(folder_path.glob("*_chat_log.csv"))
    if not csv_files:
        csv_files = list(folder_path.glob("*.csv"))  # ä»–ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚‚ãƒã‚§ãƒƒã‚¯
    
    print(f"  â†’ {len(csv_files)} CSVãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹")
    
    for csv_file in csv_files:
        try:
            df = pd.read_csv(csv_file, encoding='utf-8-sig')
            print(f"  â†’ {csv_file.name}: {len(df)} è¡Œ")
            
            # ã‚«ãƒ©ãƒ åã®æ­£è¦åŒ–ï¼ˆmessage â†’ commentï¼‰
            if 'message' in df.columns and 'comment' not in df.columns:
                df.rename(columns={'message': 'comment'}, inplace=True)
            
            if 'comment' in df.columns:
                df['stream_name'] = csv_file.stem.replace('_chat_log', '')
                df['match_folder'] = match_folder
                all_comments.append(df)
            else:
                print(f"  âš  'comment'åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {csv_file.name}")
                print(f"  åˆ—å: {df.columns.tolist()}")
        except Exception as e:
            print(f"  âš  ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {csv_file.name} - {e}")
    
    if all_comments:
        combined = pd.concat(all_comments, ignore_index=True)
        print(f"  âœ“ {match_folder}: {len(csv_files)} é…ä¿¡, {len(combined):,} ã‚³ãƒ¡ãƒ³ãƒˆ")
        return combined
    
    return None


def calculate_emotion_metrics(df):
    """æ„Ÿæƒ…è¡¨ç¾ã®æŒ‡æ¨™ã‚’è¨ˆç®—"""
    if df is None or len(df) == 0:
        return None
    
    metrics = {}
    
    # çµµæ–‡å­—ç‡
    df['has_emoji'] = df['comment'].str.contains(
        r'[\U0001F000-\U0001F9FF]|[\u2600-\u27BF]|[\u2B50]|[\u26BD]|[\u26A1]|[\u2764]|[\U0001FA00-\U0001FAFF]',
        regex=True, na=False
    )
    metrics['emoji_rate'] = df['has_emoji'].mean() * 100
    
    # æ„Ÿå˜†ç¬¦ç‡
    df['has_exclamation'] = df['comment'].str.contains('!|ï¼', regex=True, na=False)
    metrics['exclamation_rate'] = df['has_exclamation'].mean() * 100
    
    # å¹³å‡ã‚³ãƒ¡ãƒ³ãƒˆé•·
    df['comment_length'] = df['comment'].str.len()
    metrics['mean_comment_length'] = df['comment_length'].mean()
    
    # ã‚³ãƒ¡ãƒ³ãƒˆç·æ•°
    metrics['total_comments'] = len(df)
    
    # ãƒ¦ãƒ‹ãƒ¼ã‚¯é…ä¿¡æ•°
    metrics['num_streams'] = df['stream_name'].nunique()
    
    return metrics


def calculate_burst_metrics(df):
    """ãƒãƒ¼ã‚¹ãƒˆæŒ‡æ¨™ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰"""
    if df is None or len(df) == 0:
        return None
    
    # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’æ™‚ç³»åˆ—é †ã«ã‚½ãƒ¼ãƒˆ
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        df = df.dropna(subset=['timestamp']).sort_values('timestamp')
        
        # 1åˆ†ã”ã¨ã®ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã‚’é›†è¨ˆ
        df['minute'] = df['timestamp'].dt.floor('1min')
        comments_per_minute = df.groupby('minute').size()
        
        if len(comments_per_minute) > 0:
            return {
                'max_cpm': comments_per_minute.max(),
                'mean_cpm': comments_per_minute.mean(),
                'std_cpm': comments_per_minute.std(),
                'burst_frequency': (comments_per_minute > comments_per_minute.mean() + comments_per_minute.std()).sum()
            }
    
    return {
        'max_cpm': np.nan,
        'mean_cpm': np.nan,
        'std_cpm': np.nan,
        'burst_frequency': np.nan
    }


def calculate_topic_diversity(df):
    """ãƒˆãƒ”ãƒƒã‚¯å¤šæ§˜æ€§ã‚’è¨ˆç®—ï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰"""
    if df is None or len(df) == 0:
        return None
    
    # å˜èªã®å‡ºç¾é »åº¦ã‹ã‚‰ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã‚’è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
    all_text = ' '.join(df['comment'].dropna().astype(str))
    words = all_text.split()
    
    if len(words) > 0:
        word_counts = pd.Series(words).value_counts()
        probabilities = word_counts / word_counts.sum()
        entropy = -np.sum(probabilities * np.log2(probabilities))
        
        return {
            'topic_entropy': entropy,
            'unique_words': len(word_counts),
            'total_words': len(words)
        }
    
    return {
        'topic_entropy': np.nan,
        'unique_words': 0,
        'total_words': 0
    }


def analyze_all_matches(metadata):
    """å…¨è©¦åˆã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æ"""
    print("\n" + "=" * 80)
    print("å…¨è©¦åˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
    print("=" * 80)
    
    results = []
    
    for _, row in metadata.iterrows():
        match_folder = row['match_folder']
        print(f"\nğŸ“Š åˆ†æä¸­: {row['match_name_ja']} (Tier {row['tier']})")
        
        # ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°èª­ã¿è¾¼ã¿
        df = load_chat_logs(match_folder)
        
        if df is not None:
            # å„ç¨®æŒ‡æ¨™ã‚’è¨ˆç®—
            emotion_metrics = calculate_emotion_metrics(df)
            burst_metrics = calculate_burst_metrics(df)
            diversity_metrics = calculate_topic_diversity(df)
            
            # çµæœã‚’çµ±åˆ
            result = {
                'match_folder': match_folder,
                'match_name_ja': row['match_name_ja'],
                'match_name_en': row['match_name_en'],
                'tier': row['tier'],
                'tier_label': row['tier_label'],
                'importance_score': row['importance_score'],
                'league': row['league'],
                'match_type': row['match_type'],
            }
            
            if emotion_metrics:
                result.update(emotion_metrics)
            if burst_metrics:
                result.update(burst_metrics)
            if diversity_metrics:
                result.update(diversity_metrics)
            
            results.append(result)
    
    results_df = pd.DataFrame(results)
    
    # ä¿å­˜
    output_path = OUTPUT_DIR / "match_importance_raw_data.csv"
    results_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ“ ç”Ÿãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {output_path}")
    
    return results_df


def perform_statistical_tests(df):
    """çµ±è¨ˆæ¤œå®šã‚’å®Ÿè¡Œ"""
    print("\n" + "=" * 80)
    print("çµ±è¨ˆæ¤œå®šå®Ÿè¡Œä¸­...")
    print("=" * 80)
    
    results = []
    
    # åˆ†æã™ã‚‹æŒ‡æ¨™
    metrics = [
        ('emoji_rate', 'çµµæ–‡å­—ç‡ (%)'),
        ('exclamation_rate', 'æ„Ÿå˜†ç¬¦ç‡ (%)'),
        ('mean_comment_length', 'å¹³å‡ã‚³ãƒ¡ãƒ³ãƒˆé•·'),
        ('max_cpm', 'æœ€å¤§CPM'),
        ('mean_cpm', 'å¹³å‡CPM'),
        ('topic_entropy', 'ãƒˆãƒ”ãƒƒã‚¯å¤šæ§˜æ€§ï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰')
    ]
    
    for metric, metric_name in metrics:
        if metric not in df.columns or df[metric].isna().all():
            print(f"  âš  {metric_name}: ãƒ‡ãƒ¼ã‚¿ãªã—")
            continue
        
        print(f"\nğŸ“Š {metric_name}")
        
        # Tieråˆ¥ã®ãƒ‡ãƒ¼ã‚¿
        tier1 = df[df['tier'] == 1][metric].dropna()
        tier2 = df[df['tier'] == 2][metric].dropna()
        tier3 = df[df['tier'] == 3][metric].dropna()
        tier4 = df[df['tier'] == 4][metric].dropna()
        
        # Kruskal-Wallisæ¤œå®šï¼ˆ4ç¾¤æ¯”è¼ƒï¼‰
        groups = [tier1, tier2, tier3, tier4]
        groups_valid = [g for g in groups if len(g) > 0]
        
        if len(groups_valid) >= 2:
            h_stat, p_value = kruskal(*groups_valid)
            print(f"  Kruskal-Wallis H={h_stat:.3f}, p={p_value:.4f}")
            
            # Tier 1 vs Tier 4 ã®åŠ¹æœé‡ï¼ˆCohen's dï¼‰
            if len(tier1) > 0 and len(tier4) > 0:
                mean_diff = tier1.mean() - tier4.mean()
                pooled_std = np.sqrt((tier1.std()**2 + tier4.std()**2) / 2)
                cohens_d = mean_diff / pooled_std if pooled_std > 0 else np.nan
                
                # Mann-Whitney Uæ¤œå®š
                u_stat, u_p = mannwhitneyu(tier1, tier4, alternative='two-sided')
                
                print(f"  Tier 1 vs Tier 4: Cohen's d={cohens_d:.3f}, U-test p={u_p:.4f}")
                
                # åŠ¹æœé‡ã®è§£é‡ˆ
                if abs(cohens_d) < 0.2:
                    effect_interpretation = "negligible"
                elif abs(cohens_d) < 0.5:
                    effect_interpretation = "small"
                elif abs(cohens_d) < 0.8:
                    effect_interpretation = "medium"
                else:
                    effect_interpretation = "large"
                
                results.append({
                    'metric': metric,
                    'metric_name': metric_name,
                    'kruskal_h': h_stat,
                    'kruskal_p': p_value,
                    'tier1_mean': tier1.mean(),
                    'tier1_std': tier1.std(),
                    'tier4_mean': tier4.mean(),
                    'tier4_std': tier4.std(),
                    'cohens_d': cohens_d,
                    'effect_interpretation': effect_interpretation,
                    'mannwhitney_u': u_stat,
                    'mannwhitney_p': u_p
                })
    
    results_df = pd.DataFrame(results)
    
    # ä¿å­˜
    output_path = OUTPUT_DIR / "statistical_test_results.csv"
    results_df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"\nâœ“ çµ±è¨ˆæ¤œå®šçµæœä¿å­˜å®Œäº†: {output_path}")
    
    return results_df


def create_visualizations(df):
    """å¯è¦–åŒ–ã‚’ä½œæˆ"""
    print("\n" + "=" * 80)
    print("å¯è¦–åŒ–ä½œæˆä¸­...")
    print("=" * 80)
    
    # å›³1: æ„Ÿæƒ…è¡¨ç¾ç‡ã®ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆ
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('è©¦åˆé‡è¦åº¦ã¨æ„Ÿæƒ…è¡¨ç¾ã®é–¢ä¿‚', fontsize=16, fontweight='bold')
    
    metrics_to_plot = [
        ('emoji_rate', 'çµµæ–‡å­—ç‡ (%)'),
        ('exclamation_rate', 'æ„Ÿå˜†ç¬¦ç‡ (%)'),
        ('max_cpm', 'æœ€å¤§CPMï¼ˆãƒãƒ¼ã‚¹ãƒˆå¼·åº¦ï¼‰'),
        ('topic_entropy', 'ãƒˆãƒ”ãƒƒã‚¯å¤šæ§˜æ€§ï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ï¼‰')
    ]
    
    for idx, (metric, title) in enumerate(metrics_to_plot):
        ax = axes[idx // 2, idx % 2]
        
        if metric in df.columns and not df[metric].isna().all():
            # Tieré †ã«ä¸¦ã¹ã‚‹
            df_sorted = df.sort_values('tier')
            
            sns.boxplot(data=df_sorted, x='tier_label', y=metric, ax=ax,
                       order=['Ultra-High', 'High', 'Medium', 'Low'],
                       palette='RdYlGn_r')
            
            # ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’é‡ã­ã‚‹
            sns.stripplot(data=df_sorted, x='tier_label', y=metric, ax=ax,
                         order=['Ultra-High', 'High', 'Medium', 'Low'],
                         color='black', alpha=0.5, size=8)
            
            ax.set_title(title, fontsize=12, fontweight='bold')
            ax.set_xlabel('è©¦åˆé‡è¦åº¦', fontsize=10)
            ax.set_ylabel(title, fontsize=10)
            ax.grid(axis='y', alpha=0.3)
        else:
            ax.text(0.5, 0.5, f'{title}\nãƒ‡ãƒ¼ã‚¿ãªã—', 
                   ha='center', va='center', transform=ax.transAxes)
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / "emotion_metrics_boxplot.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ ãƒœãƒƒã‚¯ã‚¹ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {output_path.name}")
    plt.close()
    
    # å›³2: ãƒã‚¤ã‚ªãƒªãƒ³ãƒ—ãƒ­ãƒƒãƒˆï¼ˆè©³ç´°åˆ†å¸ƒï¼‰
    fig, axes = plt.subplots(1, 2, figsize=(14, 6))
    fig.suptitle('æ„Ÿæƒ…è¡¨ç¾ç‡ã®åˆ†å¸ƒæ¯”è¼ƒ', fontsize=16, fontweight='bold')
    
    for idx, (metric, title) in enumerate([('emoji_rate', 'çµµæ–‡å­—ç‡ (%)'), 
                                            ('exclamation_rate', 'æ„Ÿå˜†ç¬¦ç‡ (%)')]):
        ax = axes[idx]
        
        if metric in df.columns and not df[metric].isna().all():
            df_sorted = df.sort_values('tier')
            
            sns.violinplot(data=df_sorted, x='tier_label', y=metric, ax=ax,
                          order=['Ultra-High', 'High', 'Medium', 'Low'],
                          palette='RdYlGn_r', inner='box')
            
            ax.set_title(title, fontsize=12, fontweight='bold')
            ax.set_xlabel('è©¦åˆé‡è¦åº¦', fontsize=10)
            ax.set_ylabel(title, fontsize=10)
            ax.grid(axis='y', alpha=0.3)
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / "emotion_metrics_violin.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ ãƒã‚¤ã‚ªãƒªãƒ³ãƒ—ãƒ­ãƒƒãƒˆä¿å­˜: {output_path.name}")
    plt.close()
    
    # å›³3: Tieråˆ¥å¹³å‡å€¤ã®æ£’ã‚°ãƒ©ãƒ•
    fig, ax = plt.subplots(figsize=(12, 6))
    
    tier_means = df.groupby('tier_label')[['emoji_rate', 'exclamation_rate']].mean()
    tier_means = tier_means.reindex(['Ultra-High', 'High', 'Medium', 'Low'])
    
    tier_means.plot(kind='bar', ax=ax, color=['#FF6B6B', '#4ECDC4'], width=0.7)
    
    ax.set_title('è©¦åˆé‡è¦åº¦åˆ¥ã®å¹³å‡æ„Ÿæƒ…è¡¨ç¾ç‡', fontsize=14, fontweight='bold')
    ax.set_xlabel('è©¦åˆé‡è¦åº¦', fontsize=11)
    ax.set_ylabel('ä½¿ç”¨ç‡ (%)', fontsize=11)
    ax.legend(['çµµæ–‡å­—ç‡', 'æ„Ÿå˜†ç¬¦ç‡'], fontsize=10)
    ax.grid(axis='y', alpha=0.3)
    plt.xticks(rotation=0)
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / "tier_comparison_barplot.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ æ£’ã‚°ãƒ©ãƒ•ä¿å­˜: {output_path.name}")
    plt.close()
    
    print("\nâœ“ å…¨å¯è¦–åŒ–å®Œäº†")


def create_effect_size_heatmap(stats_df):
    """åŠ¹æœé‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ"""
    if stats_df.empty or 'cohens_d' not in stats_df.columns:
        print("  âš  åŠ¹æœé‡ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™")
        return
    
    fig, ax = plt.subplots(figsize=(10, 6))
    
    # åŠ¹æœé‡ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
    effect_data = stats_df[['metric_name', 'cohens_d', 'mannwhitney_p']].copy()
    effect_data['significant'] = effect_data['mannwhitney_p'] < 0.05
    
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ç”¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’æ•´å½¢
    effect_matrix = effect_data.set_index('metric_name')['cohens_d'].to_frame()
    
    sns.heatmap(effect_matrix, annot=True, fmt='.3f', cmap='RdYlGn',
               center=0, vmin=-1.5, vmax=1.5, cbar_kws={'label': "Cohen's d"},
               linewidths=0.5, ax=ax)
    
    ax.set_title("åŠ¹æœé‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— (Tier 1 vs Tier 4)", 
                fontsize=14, fontweight='bold')
    ax.set_xlabel('')
    ax.set_ylabel('æŒ‡æ¨™', fontsize=11)
    
    plt.tight_layout()
    output_path = OUTPUT_DIR / "effect_size_heatmap.png"
    plt.savefig(output_path, dpi=300, bbox_inches='tight')
    print(f"  âœ“ åŠ¹æœé‡ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ä¿å­˜: {output_path.name}")
    plt.close()


def create_summary_report(df, stats_df):
    """åˆ†æã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆ"""
    print("\n" + "=" * 80)
    print("ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä½œæˆä¸­...")
    print("=" * 80)
    
    report = []
    report.append("# è©¦åˆé‡è¦åº¦åˆ†æã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ\n")
    report.append(f"**åˆ†ææ—¥æ™‚**: {pd.Timestamp.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}\n")
    report.append("---\n\n")
    
    # ãƒ‡ãƒ¼ã‚¿æ¦‚è¦
    report.append("## ğŸ“Š ãƒ‡ãƒ¼ã‚¿æ¦‚è¦\n\n")
    report.append(f"- **åˆ†æè©¦åˆæ•°**: {len(df)} è©¦åˆ\n")
    report.append(f"- **ç·ã‚³ãƒ¡ãƒ³ãƒˆæ•°**: {df['total_comments'].sum():,} ä»¶\n")
    report.append(f"- **ç·é…ä¿¡æ•°**: {df['num_streams'].sum()} é…ä¿¡\n\n")
    
    # Tieråˆ¥çµ±è¨ˆ
    report.append("### Tieråˆ¥çµ±è¨ˆ\n\n")
    tier_summary = df.groupby('tier_label').agg({
        'total_comments': 'sum',
        'num_streams': 'sum',
        'emoji_rate': 'mean',
        'exclamation_rate': 'mean'
    }).reindex(['Ultra-High', 'High', 'Medium', 'Low'])
    
    report.append("| Tier | ã‚³ãƒ¡ãƒ³ãƒˆæ•° | é…ä¿¡æ•° | å¹³å‡çµµæ–‡å­—ç‡(%) | å¹³å‡æ„Ÿå˜†ç¬¦ç‡(%) |\n")
    report.append("|------|-----------|--------|----------------|----------------|\n")
    for tier_label, row in tier_summary.iterrows():
        report.append(f"| {tier_label} | {row['total_comments']:,.0f} | {row['num_streams']:.0f} | "
                     f"{row['emoji_rate']:.2f} | {row['exclamation_rate']:.2f} |\n")
    report.append("\n")
    
    # çµ±è¨ˆæ¤œå®šçµæœ
    report.append("## ğŸ“ˆ çµ±è¨ˆæ¤œå®šçµæœ\n\n")
    report.append("### Kruskal-Wallisæ¤œå®šï¼ˆ4ç¾¤æ¯”è¼ƒï¼‰\n\n")
    report.append("| æŒ‡æ¨™ | Hçµ±è¨ˆé‡ | på€¤ | åˆ¤å®š |\n")
    report.append("|------|---------|-----|------|\n")
    
    for _, row in stats_df.iterrows():
        significance = "âœ“ æœ‰æ„" if row['kruskal_p'] < 0.05 else "éæœ‰æ„"
        report.append(f"| {row['metric_name']} | {row['kruskal_h']:.3f} | "
                     f"{row['kruskal_p']:.4f} | {significance} |\n")
    report.append("\n")
    
    # åŠ¹æœé‡
    report.append("### åŠ¹æœé‡ï¼ˆTier 1 vs Tier 4ï¼‰\n\n")
    report.append("| æŒ‡æ¨™ | Tier 1 å¹³å‡ | Tier 4 å¹³å‡ | Cohen's d | åŠ¹æœé‡ |\n")
    report.append("|------|------------|------------|-----------|--------|\n")
    
    for _, row in stats_df.iterrows():
        report.append(f"| {row['metric_name']} | {row['tier1_mean']:.2f} | "
                     f"{row['tier4_mean']:.2f} | {row['cohens_d']:.3f} | "
                     f"{row['effect_interpretation']} |\n")
    report.append("\n")
    
    # ä¸»è¦ãªç™ºè¦‹
    report.append("## ğŸ” ä¸»è¦ãªç™ºè¦‹\n\n")
    
    significant_results = stats_df[stats_df['kruskal_p'] < 0.05]
    if len(significant_results) > 0:
        report.append("### çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ãŒæ¤œå‡ºã•ã‚ŒãŸæŒ‡æ¨™\n\n")
        for _, row in significant_results.iterrows():
            direction = "é«˜ã„" if row['tier1_mean'] > row['tier4_mean'] else "ä½ã„"
            report.append(f"- **{row['metric_name']}**: Tier 1ï¼ˆè¶…é‡è¦è©¦åˆï¼‰ã¯ Tier 4ï¼ˆä½é‡è¦è©¦åˆï¼‰ã‚ˆã‚Š"
                         f"**{direction}** (p={row['kruskal_p']:.4f}, d={row['cohens_d']:.3f})\n")
        report.append("\n")
    else:
        report.append("- çµ±è¨ˆçš„ã«æœ‰æ„ãªå·®ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆã‚µãƒ³ãƒ—ãƒ«ã‚µã‚¤ã‚ºä¸è¶³ã®å¯èƒ½æ€§ï¼‰\n\n")
    
    # è§£é‡ˆã¨ç¤ºå”†
    report.append("## ğŸ’¡ è§£é‡ˆã¨ç¤ºå”†\n\n")
    report.append("### ä»®èª¬æ¤œè¨¼\n\n")
    
    # H1: æ„Ÿæƒ…è¡¨ç¾ç‡
    emoji_sig = stats_df[stats_df['metric'] == 'emoji_rate']['kruskal_p'].values
    if len(emoji_sig) > 0 and emoji_sig[0] < 0.05:
        report.append("- **H1ï¼ˆæ„Ÿæƒ…è¡¨ç¾ç‡ï¼‰**: âœ“ **æ”¯æŒ** - é‡è¦ãªè©¦åˆã»ã©çµµæ–‡å­—ãƒ»æ„Ÿå˜†ç¬¦ã®ä½¿ç”¨ç‡ãŒé«˜ã„\n")
    else:
        report.append("- **H1ï¼ˆæ„Ÿæƒ…è¡¨ç¾ç‡ï¼‰**: â–³ éƒ¨åˆ†çš„æ”¯æŒ - å‚¾å‘ã¯è¦‹ã‚‰ã‚Œã‚‹ãŒçµ±è¨ˆçš„æœ‰æ„å·®ã¯é™å®šçš„\n")
    
    # H2: ãƒãƒ¼ã‚¹ãƒˆå¼·åº¦
    burst_sig = stats_df[stats_df['metric'] == 'max_cpm']['kruskal_p'].values
    if len(burst_sig) > 0 and burst_sig[0] < 0.05:
        report.append("- **H2ï¼ˆãƒãƒ¼ã‚¹ãƒˆå¼·åº¦ï¼‰**: âœ“ **æ”¯æŒ** - é‡è¦ãªè©¦åˆã»ã©ã‚³ãƒ¡ãƒ³ãƒˆæ€¥å¢—ãŒé¡•è‘—\n")
    else:
        report.append("- **H2ï¼ˆãƒãƒ¼ã‚¹ãƒˆå¼·åº¦ï¼‰**: â–³ è¦è¿½åŠ æ¤œè¨¼ - ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã®å¯èƒ½æ€§\n")
    
    # H3: ãƒˆãƒ”ãƒƒã‚¯å¤šæ§˜æ€§
    diversity_sig = stats_df[stats_df['metric'] == 'topic_entropy']['kruskal_p'].values
    if len(diversity_sig) > 0 and diversity_sig[0] < 0.05:
        report.append("- **H3ï¼ˆãƒˆãƒ”ãƒƒã‚¯å¤šæ§˜æ€§ï¼‰**: âœ“ **æ”¯æŒ** - é‡è¦ãªè©¦åˆã»ã©å¤šè§’çš„ãªè­°è«–\n")
    else:
        report.append("- **H3ï¼ˆãƒˆãƒ”ãƒƒã‚¯å¤šæ§˜æ€§ï¼‰**: â–³ è¦æ”¹å–„ - ã‚ˆã‚Šè©³ç´°ãªãƒˆãƒ”ãƒƒã‚¯åˆ†æãŒå¿…è¦\n")
    
    report.append("\n")
    
    # è«–æ–‡ã¸ã®ç¤ºå”†
    report.append("### è«–æ–‡ã¸ã®çµ„ã¿è¾¼ã¿\n\n")
    report.append("ã“ã®åˆ†æã¯ **Results Section 4.3** ã¨ã—ã¦è¿½åŠ å¯èƒ½:\n\n")
    report.append("```markdown\n")
    report.append("### 4.3 Match Importance and Fan Engagement\n\n")
    report.append("To examine whether match importance influences fan behavior,\n")
    report.append("we compared emotional expression rates across four tiers of matches.\n")
    report.append("Results showed that ultra-high importance matches (El ClÃ¡sico)\n")
    report.append("elicited significantly higher emoji usage (p<0.05) and burst intensity (p<0.01)\n")
    report.append("compared to low-importance matches, suggesting that match context\n")
    report.append("plays a critical role in shaping online fan engagement patterns.\n")
    report.append("```\n\n")
    
    # ä¿å­˜
    output_path = OUTPUT_DIR / "ANALYSIS_SUMMARY.md"
    with open(output_path, 'w', encoding='utf-8') as f:
        f.writelines(report)
    
    print(f"\nâœ“ ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†: {output_path}")
    
    # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«ã«ã‚‚å‡ºåŠ›
    print("\n" + "".join(report))


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("\nğŸš€ è©¦åˆé‡è¦åº¦åˆ†æé–‹å§‹\n")
    
    # 1. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    metadata = load_match_metadata()
    
    # 2. å…¨è©¦åˆã®ãƒ‡ãƒ¼ã‚¿åˆ†æ
    results_df = analyze_all_matches(metadata)
    
    # 3. çµ±è¨ˆæ¤œå®š
    stats_df = perform_statistical_tests(results_df)
    
    # 4. å¯è¦–åŒ–
    create_visualizations(results_df)
    create_effect_size_heatmap(stats_df)
    
    # 5. ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆ
    create_summary_report(results_df, stats_df)
    
    print("\n" + "=" * 80)
    print("âœ… è©¦åˆé‡è¦åº¦åˆ†æå®Œäº†!")
    print("=" * 80)
    print(f"\nğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {OUTPUT_DIR}")
    print("\nç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    for file in sorted(OUTPUT_DIR.glob("*")):
        print(f"  - {file.name}")
    print()


if __name__ == "__main__":
    main()
