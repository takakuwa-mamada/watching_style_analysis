#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç¾çŠ¶åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ: ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºã®å“è³ªã‚’å®šé‡è©•ä¾¡
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from pathlib import Path

def analyze_current_status():
    """ç¾çŠ¶ã®è©³ç´°åˆ†æ"""
    
    print('='*60)
    print('ğŸ“Š ç¾çŠ¶åˆ†æ: ã‚¤ãƒ™ãƒ³ãƒˆæ¤œå‡ºã®å“è³ªè©•ä¾¡')
    print('='*60)
    
    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = pd.read_csv('output/event_to_event_pairs.csv')
    
    # combined_scoreã‚’similarityã¨ã—ã¦ä½¿ç”¨
    if 'similarity' not in df.columns:
        if 'combined_score' in df.columns:
            df['similarity'] = df['combined_score']
        elif 'main_similarity' in df.columns:
            df['similarity'] = df['main_similarity']
    
    # é…ä¿¡è€…æ•°ã‚’è¨ˆç®—ï¼ˆä»®ã«4ã¨è¨­å®šï¼‰
    if 'num_broadcasters' not in df.columns:
        df['num_broadcasters'] = 4  # ç°¡æ˜“çš„ã«å›ºå®šå€¤
    
    # åŸºæœ¬çµ±è¨ˆ
    print(f'\nã€åŸºæœ¬çµ±è¨ˆã€‘')
    print(f'  ç·ãƒšã‚¢æ•°: {len(df)}')
    print(f'  å¹³å‡é¡ä¼¼åº¦: {df["similarity"].mean():.3f}')
    print(f'  æœ€å¤§é¡ä¼¼åº¦: {df["similarity"].max():.3f}')
    print(f'  æ¨™æº–åå·®: {df["similarity"].std():.3f}')
    
    # å“è³ªåˆ†å¸ƒ
    print(f'\nã€å“è³ªåˆ†å¸ƒã€‘')
    very_high = len(df[df['similarity'] > 0.8])
    high = len(df[(df['similarity'] > 0.6) & (df['similarity'] <= 0.8)])
    medium = len(df[(df['similarity'] > 0.4) & (df['similarity'] <= 0.6)])
    low = len(df[df['similarity'] <= 0.4])
    
    print(f'  Very High (>0.8): {very_high} ({very_high/len(df)*100:.1f}%)')
    print(f'  High (0.6-0.8): {high} ({high/len(df)*100:.1f}%)')
    print(f'  Medium (0.4-0.6): {medium} ({medium/len(df)*100:.1f}%)')
    print(f'  Low (<0.4): {low} ({low/len(df)*100:.1f}%)')
    
    # ãƒˆãƒ”ãƒƒã‚¯ä¸€è‡´
    print(f'\nã€ãƒˆãƒ”ãƒƒã‚¯ä¸€è‡´ã€‘')
    topic_nonzero = len(df[df['topic_jaccard'] > 0])
    topic_high = len(df[df['topic_jaccard'] > 0.5])
    topic_perfect = len(df[df['topic_jaccard'] == 1.0])
    
    print(f'  topic_jaccard > 0: {topic_nonzero} ({topic_nonzero/len(df)*100:.1f}%)')
    print(f'  topic_jaccard > 0.5: {topic_high} ({topic_high/len(df)*100:.1f}%)')
    print(f'  topic_jaccard = 1.0: {topic_perfect} ({topic_perfect/len(df)*100:.1f}%)')
    
    # æ™‚é–“çš„ä¸€è²«æ€§
    print(f'\nã€æ™‚é–“çš„ä¸€è²«æ€§ã‚¹ã‚³ã‚¢ã€‘')
    high_sim = df[df['similarity'] > 0.7]
    low_sim = df[df['similarity'] < 0.3]
    
    if len(high_sim) > 0 and len(low_sim) > 0:
        high_time = high_sim['time_diff_bins'].mean()
        low_time = low_sim['time_diff_bins'].mean()
        consistency = low_time / (high_time + 1e-6)
        print(f'  é«˜é¡ä¼¼ãƒšã‚¢ã®å¹³å‡æ™‚é–“å·®: {high_time:.2f} bins')
        print(f'  ä½é¡ä¼¼ãƒšã‚¢ã®å¹³å‡æ™‚é–“å·®: {low_time:.2f} bins')
        print(f'  æ™‚é–“çš„ä¸€è²«æ€§ã‚¹ã‚³ã‚¢: {consistency:.2f}x')
        print(f'  â†’ é¡ä¼¼ãƒšã‚¢ã¯éé¡ä¼¼ãƒšã‚¢ã‚ˆã‚Š{consistency:.1f}å€æ™‚é–“ãŒè¿‘ã„ âœ“')
    else:
        print('  ãƒ‡ãƒ¼ã‚¿ä¸è¶³ã«ã‚ˆã‚Šè¨ˆç®—ã§ãã¾ã›ã‚“')
    
    # åŸ‹ã‚è¾¼ã¿ vs ãƒˆãƒ”ãƒƒã‚¯ç›¸é–¢
    print(f'\nã€åŸ‹ã‚è¾¼ã¿é¡ä¼¼åº¦ vs ãƒˆãƒ”ãƒƒã‚¯é¡ä¼¼åº¦ã€‘')
    corr = df['embedding_similarity'].corr(df['topic_jaccard'])
    print(f'  ç›¸é–¢ä¿‚æ•°: {corr:.3f}')
    if corr > 0.5:
        print(f'  â†’ å¼·ã„æ­£ã®ç›¸é–¢ âœ“')
    elif corr > 0.3:
        print(f'  â†’ ä¸­ç¨‹åº¦ã®æ­£ã®ç›¸é–¢')
    else:
        print(f'  â†’ å¼±ã„ç›¸é–¢ âš ï¸')
    
    # Top 5é«˜å“è³ªãƒšã‚¢
    print(f'\nã€Top 5 é«˜å“è³ªãƒšã‚¢ã€‘')
    top5 = df.nlargest(5, 'similarity')
    for i, (idx, row) in enumerate(top5.iterrows(), 1):
        event_a = int(row["event_A_id"]) if "event_A_id" in row else int(row.get("event_A", 0))
        event_b = int(row["event_B_id"]) if "event_B_id" in row else int(row.get("event_B", 0))
        print(f'\n  {i}. Event {event_a} â†” {event_b}')
        print(f'     ç·åˆé¡ä¼¼åº¦: {row["similarity"]:.3f}')
        print(f'     embedding: {row["embedding_similarity"]:.3f}')
        print(f'     topic_jaccard: {row["topic_jaccard"]:.3f}')
        print(f'     æ™‚é–“å·®: {int(row["time_diff_bins"])} bins')
        if "num_broadcasters" in row:
            print(f'     é…ä¿¡è€…æ•°: {int(row["num_broadcasters"])}')
    
    # å•é¡Œç‚¹ã®ç‰¹å®š
    print(f'\nã€å•é¡Œç‚¹ã®ç‰¹å®šã€‘')
    problems = []
    
    if df['similarity'].mean() < 0.3:
        problems.append('âš ï¸  å¹³å‡é¡ä¼¼åº¦ãŒä½ã„ (<0.3)')
    if topic_nonzero / len(df) < 0.3:
        problems.append('âš ï¸  ãƒˆãƒ”ãƒƒã‚¯ä¸€è‡´ç‡ãŒä½ã„ (<30%)')
    if very_high < 3:
        problems.append('âš ï¸  é«˜å“è³ªãƒšã‚¢ãŒå°‘ãªã„ (<3)')
    if df['similarity'].std() < 0.1:
        problems.append('âš ï¸  é¡ä¼¼åº¦ã®åˆ†æ•£ãŒå°ã•ã„ï¼ˆè­˜åˆ¥åŠ›ä¸è¶³ï¼‰')
    
    if problems:
        for p in problems:
            print(f'  {p}')
    else:
        print('  âœ… ç›®ç«‹ã£ãŸå•é¡Œãªã—')
    
    # æ”¹å–„ææ¡ˆ
    print(f'\nã€æ”¹å–„ææ¡ˆã€‘')
    suggestions = []
    
    if topic_nonzero / len(df) < 0.3:
        suggestions.append('1. N-gramæŠ½å‡ºã®min_dfãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’èª¿æ•´ï¼ˆç¾åœ¨: 2 â†’ 1ã«ä¸‹ã’ã‚‹ï¼‰')
    if df['similarity'].mean() < 0.3:
        suggestions.append('2. é‡ã¿ä»˜ã‘ã‚’èª¿æ•´ï¼ˆembeddingé‡è¦– â†’ topicé‡è¦–ï¼‰')
    if very_high < 3:
        suggestions.append('3. é–¾å€¤ã‚’ä¸‹ã’ã¦æ¤œå‡ºæ„Ÿåº¦ã‚’ä¸Šã’ã‚‹')
    
    if suggestions:
        for s in suggestions:
            print(f'  {s}')
    else:
        print('  â†’ ç¾åœ¨ã®è¨­å®šã§è‰¯å¥½')
    
    print('\n' + '='*60)
    
    return df

def create_visualizations(df):
    """å¯è¦–åŒ–ã‚’ä½œæˆ"""
    
    print('\nğŸ“Š å¯è¦–åŒ–ã‚’ä½œæˆä¸­...')
    
    output_dir = Path('output')
    
    # 1. é¡ä¼¼åº¦åˆ†å¸ƒ
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    
    # 1-1. ç·åˆé¡ä¼¼åº¦ã®ãƒ’ã‚¹ãƒˆã‚°ãƒ©ãƒ 
    axes[0, 0].hist(df['similarity'], bins=20, edgecolor='black', alpha=0.7)
    axes[0, 0].axvline(df['similarity'].mean(), color='red', linestyle='--', 
                       label=f'Mean: {df["similarity"].mean():.3f}')
    axes[0, 0].set_xlabel('Similarity Score')
    axes[0, 0].set_ylabel('Frequency')
    axes[0, 0].set_title('Distribution of Event Similarity')
    axes[0, 0].legend()
    axes[0, 0].grid(alpha=0.3)
    
    # 1-2. Embedding vs Topicæ•£å¸ƒå›³
    scatter = axes[0, 1].scatter(df['embedding_similarity'], df['topic_jaccard'],
                                 c=df['similarity'], cmap='viridis', alpha=0.6, s=50)
    axes[0, 1].set_xlabel('Embedding Similarity')
    axes[0, 1].set_ylabel('Topic Jaccard')
    axes[0, 1].set_title('Embedding vs Topic Similarity')
    plt.colorbar(scatter, ax=axes[0, 1], label='Combined Similarity')
    axes[0, 1].grid(alpha=0.3)
    
    # 1-3. æ™‚é–“å·® vs é¡ä¼¼åº¦
    axes[1, 0].scatter(df['time_diff_bins'], df['similarity'], alpha=0.6, s=50)
    axes[1, 0].set_xlabel('Time Difference (bins)')
    axes[1, 0].set_ylabel('Similarity Score')
    axes[1, 0].set_title('Temporal Distance vs Similarity')
    axes[1, 0].grid(alpha=0.3)
    
    # 1-4. å“è³ªåˆ†å¸ƒï¼ˆæ£’ã‚°ãƒ©ãƒ•ï¼‰
    categories = ['Very High\n(>0.8)', 'High\n(0.6-0.8)', 'Medium\n(0.4-0.6)', 'Low\n(<0.4)']
    counts = [
        len(df[df['similarity'] > 0.8]),
        len(df[(df['similarity'] > 0.6) & (df['similarity'] <= 0.8)]),
        len(df[(df['similarity'] > 0.4) & (df['similarity'] <= 0.6)]),
        len(df[df['similarity'] <= 0.4])
    ]
    colors = ['#2ecc71', '#3498db', '#f39c12', '#e74c3c']
    axes[1, 1].bar(categories, counts, color=colors, edgecolor='black', alpha=0.7)
    axes[1, 1].set_ylabel('Number of Pairs')
    axes[1, 1].set_title('Quality Distribution')
    axes[1, 1].grid(axis='y', alpha=0.3)
    
    # æ•°å€¤ã‚’æ£’ã®ä¸Šã«è¡¨ç¤º
    for i, (cat, count) in enumerate(zip(categories, counts)):
        axes[1, 1].text(i, count + 0.5, str(count), ha='center', va='bottom', fontweight='bold')
    
    plt.tight_layout()
    plt.savefig(output_dir / 'current_status_analysis.png', dpi=300, bbox_inches='tight')
    print(f'  âœ“ ä¿å­˜: output/current_status_analysis.png')
    
    # 2. ç›¸é–¢ãƒãƒˆãƒªãƒƒã‚¯ã‚¹
    fig, ax = plt.subplots(figsize=(8, 6))
    
    corr_cols = ['embedding_similarity', 'lexical_similarity', 'topic_jaccard', 
                 'temporal_correlation', 'similarity']
    corr_matrix = df[corr_cols].corr()
    
    # æ‰‹å‹•ã§ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’ä½œæˆ
    im = ax.imshow(corr_matrix, cmap='coolwarm', vmin=-1, vmax=1, aspect='auto')
    
    # è»¸ãƒ©ãƒ™ãƒ«
    ax.set_xticks(range(len(corr_cols)))
    ax.set_yticks(range(len(corr_cols)))
    ax.set_xticklabels(corr_cols, rotation=45, ha='right')
    ax.set_yticklabels(corr_cols)
    
    # æ•°å€¤ã‚’è¡¨ç¤º
    for i in range(len(corr_cols)):
        for j in range(len(corr_cols)):
            text = ax.text(j, i, f'{corr_matrix.iloc[i, j]:.3f}',
                          ha="center", va="center", color="black", fontsize=9)
    
    ax.set_title('Correlation Matrix of Similarity Components')
    plt.colorbar(im, ax=ax, label='Correlation')
    
    plt.tight_layout()
    plt.savefig(output_dir / 'correlation_matrix.png', dpi=300, bbox_inches='tight')
    print(f'  âœ“ ä¿å­˜: output/correlation_matrix.png')
    
    plt.close('all')

if __name__ == '__main__':
    df = analyze_current_status()
    create_visualizations(df)
    
    print('\nâœ… åˆ†æå®Œäº†ï¼')
    print('æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—: output/current_status_analysis.png ã‚’ç¢ºèª')
